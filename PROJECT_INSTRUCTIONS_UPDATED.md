# Project Instructions: Agentic AI Development

## Project Identity

**Repository Name:** `agentic_ai_development`  
**Purpose:** Build practical, production-ready implementations of five core agentic AI capabilities  
**Philosophy:** Pragmatic realism over hype. Working code over theoretical frameworks. Documentation of failure modes alongside success patterns.

---

## Core Objectives

We are building five distinct but interconnected agentic capabilities:

1. **Prompt Routing** â†’ Dynamic intent detection and routing logic
2. **Query Writing** â†’ Self-constructing database/API queries
3. **Data Processing** â†’ Transform raw inputs into usable outputs
4. **Tool Orchestration** â†’ Chaining APIs with fallback handling
5. **Decision Support** â†’ Multi-step planning and prioritization

Each capability must be:
- Independently testable
- Clearly documented (including when it breaks)
- Implementable in real projects
- Backed by examples from actual use cases

---

## Working Principles

### 1. **Documentation is Constitutive, Not Decorative**

Every pattern, every function, every architectural decision gets documented *as we build*, not after. 

The PKB (Personal Knowledge Base) serves as our conceptual foundationâ€”we summarize external documentation into markdown files that become our reference material. This isn't busywork. It's how we internalize patterns and avoid cargo-cult implementations.

**âœ… PKB STATUS: COMPLETE (12/12 documents)**

### 2. **Code Standards**

- **Python 3.10+** (for match statements, improved type hints)
- **Type hints everywhere** (Pydantic models for complex structures)
- **Docstrings follow Google style** (readable, practical)
- **Tests are non-negotiable** (pytest, with both unit and integration tests)
- **Error handling is explicit** (no silent failures, clear error messages)

### 3. **File Organization**

```
agentic_ai_development/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/               # CI/CD pipelines
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PKB/                     # âœ… Personal Knowledge Base (12 docs complete)
â”‚   â”‚   â”œâ”€â”€ anthropic_tool_use.md
â”‚   â”‚   â”œâ”€â”€ langchain_agents.md
â”‚   â”‚   â”œâ”€â”€ react_pattern.md
â”‚   â”‚   â”œâ”€â”€ langchain_tools.md
â”‚   â”‚   â”œâ”€â”€ pydantic_validation.md
â”‚   â”‚   â”œâ”€â”€ openai_function_calling.md
â”‚   â”‚   â”œâ”€â”€ anthropic_prompt_engineering.md
â”‚   â”‚   â”œâ”€â”€ openai_prompt_engineering.md
â”‚   â”‚   â”œâ”€â”€ rag_and_embeddings.md
â”‚   â”‚   â”œâ”€â”€ llamaindex_query_engines.md
â”‚   â”‚   â”œâ”€â”€ langgraph_workflows.md
â”‚   â”‚   â””â”€â”€ agent_testing_evaluation_observability.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # System architecture design
â”‚   â”œâ”€â”€ PATTERNS.md              # Common patterns discovered
â”‚   â””â”€â”€ API.md                   # API documentation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prompt_routing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ classifier.py
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â””â”€â”€ handlers/
â”‚   â”œâ”€â”€ query_writing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sql_generator.py
â”‚   â”‚   â”œâ”€â”€ api_query_builder.py
â”‚   â”‚   â””â”€â”€ schema_manager.py
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ transformers.py
â”‚   â”‚   â”œâ”€â”€ validators.py
â”‚   â”‚   â””â”€â”€ pipelines.py
â”‚   â”œâ”€â”€ tool_orchestration/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”‚   â”œâ”€â”€ tool_registry.py
â”‚   â”‚   â””â”€â”€ fallback_handler.py
â”‚   â”œâ”€â”€ decision_support/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”‚   â”œâ”€â”€ recommender.py
â”‚   â”‚   â””â”€â”€ explainer.py
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â””â”€â”€ integrations/            # Observability, monitoring
â”‚       â”œâ”€â”€ langsmith.py
â”‚       â”œâ”€â”€ phoenix.py
â”‚       â””â”€â”€ cost_tracker.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                    # Fast, mocked tests
â”‚   â”œâ”€â”€ integration/             # Real LLM calls
â”‚   â”œâ”€â”€ fixtures/                # Test data
â”‚   â””â”€â”€ conftest.py              # Pytest configuration
â”œâ”€â”€ examples/                     # Working demonstrations
â”‚   â”œâ”€â”€ basic_routing.py
â”‚   â”œâ”€â”€ sql_query_generation.py
â”‚   â”œâ”€â”€ data_pipeline.py
â”‚   â”œâ”€â”€ tool_chain.py
â”‚   â””â”€â”€ decision_workflow.py
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ setup_env.py
â”‚   â”œâ”€â”€ run_evals.py
â”‚   â””â”€â”€ cost_report.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt         # Development dependencies
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ README.md
â””â”€â”€ PROJECT_INSTRUCTIONS.md      # This file
```

### 4. **Naming Conventions**

- **Modules:** lowercase_with_underscores
- **Classes:** PascalCase
- **Functions:** lowercase_with_underscores
- **Constants:** UPPERCASE_WITH_UNDERSCORES
- **Private:** _leading_underscore
- **PKB files:** `service_topic.md` (e.g., `anthropic_tool_use.md`)

---

## Development Workflow

### âœ… Phase 1: Knowledge Foundation (COMPLETE)
1. âœ… Identified 12 key documentation sources
2. âœ… Summarized each into PKB markdown files
3. âœ… Extracted patterns, best practices, failure modes
4. âœ… Documented connections between different sources

**Deliverables:**
- 12 comprehensive PKB documents (700-1000 lines each)
- Clear understanding of all five capabilities
- Foundation for implementation decisions

---

### ðŸ”„ Phase 2: Architecture Design (IN PROGRESS)

**Timeline:** 2-3 days

**Goals:**
1. Design overall system architecture
2. Define interfaces between components
3. Establish data flow patterns
4. Document design decisions and trade-offs
5. Create ARCHITECTURE.md

**Key Decisions to Document:**
- Which LLM providers to support (Anthropic, OpenAI, or both?)
- Vector database choice (ChromaDB for dev, Pinecone for prod?)
- State management strategy (LangGraph checkpoints?)
- Error handling patterns
- Testing strategy
- Observability approach (LangSmith, Phoenix, both?)

**Deliverables:**
- `docs/ARCHITECTURE.md` - System design document
- Interface definitions (Pydantic models)
- Sequence diagrams for key workflows
- Technology stack decisions documented

---

### ðŸš€ Phase 3: Implementation (RAPID EXECUTION - Claude Code)

**Timeline:** 7-8 days (using $1000 Claude Code credit)**

**Strategy:** Build all five capabilities in parallel using Claude Code's autonomous coding environment.

**Week 1 Sprint:**

**Day 1-2: Foundation & Routing**
- Set up project structure
- Implement common utilities (config, exceptions, models)
- Build Prompt Routing capability (classifier + router + handlers)
- Unit tests for routing logic
- Integration tests with real LLMs (budget: $20)

**Day 3-4: Query Writing & Data Processing**
- SQL/API query generation
- Schema management
- Data transformation pipelines
- Validation logic
- Tests for both capabilities (budget: $30)

**Day 5-6: Tool Orchestration & Decision Support**
- Tool registry and orchestrator
- Fallback handling
- Decision analyzer and recommender
- Integration tests (budget: $40)

**Day 7-8: Integration, Examples & Testing**
- Connect all capabilities
- Build working examples (5 complete demos)
- Comprehensive test suite
- Documentation finalization
- Performance testing (budget: $50)

**Total Budget:** ~$140 in LLM costs, rest for compute/iterations

---

### Phase 4: Production Readiness (POST-CREDIT)

**Timeline:** Ongoing

1. Performance optimization
2. Production deployment patterns
3. Real-world validation
4. Community feedback incorporation
5. Blog posts / documentation site

---

## Claude Code Strategy ($1000 Credit, 11 Days)

### Why Claude Code?

**Advantages for This Project:**
- Autonomous coding with full context of PKB
- Can read all 12 PKB documents and apply patterns
- Faster iteration than manual coding
- Better at maintaining consistency across modules
- Natural for implementing patterns from documentation

**Credit Usage:**
- $1000 credit = ~6.7M output tokens at $0.15/1M
- Or ~33M input tokens at $0.03/1M
- Realistically: ~200-300 hours of coding assistance
- Perfect for rapid implementation phase

### Execution Plan

**Day 1: Setup & Architecture**
- Push completed PKB to GitHub
- Initialize project structure
- Create ARCHITECTURE.md with Claude Code
- Set up development environment
- Budget: $50

**Days 2-3: Core Implementation**
- Implement common utilities
- Build prompt routing (capability #1)
- Budget: $150

**Days 4-5: Data Capabilities**
- Query writing (capability #2)
- Data processing (capability #3)
- Budget: $150

**Days 6-7: Advanced Capabilities**
- Tool orchestration (capability #4)
- Decision support (capability #5)
- Budget: $150

**Days 8-9: Integration & Testing**
- Connect all capabilities
- Comprehensive test suite
- Working examples
- Budget: $200

**Days 10-11: Polish & Documentation**
- Fix bugs discovered in testing
- Complete README
- API documentation
- Performance optimization
- Budget: $200

**Buffer:** $100 for unexpected iterations/debugging

### Daily Workflow with Claude Code

**Morning (Planning):**
1. Review previous day's work
2. Define today's specific goals
3. Create Claude Code task with PKB references
4. Example: "Implement SQL query generator using patterns from `query_writing.md` and `pydantic_validation.md`"

**Afternoon (Execution):**
1. Let Claude Code implement
2. Review generated code
3. Request refinements
4. Run tests

**Evening (Validation):**
1. Integration testing
2. Cost tracking
3. Update progress notes
4. Plan next day

### Cost Control

**Monitor Daily:**
```python
# Track Claude Code usage
daily_budget = 1000 / 11  # ~$91/day
if today_cost > daily_budget:
    # Pause, review, adjust strategy
```

**Optimization:**
- Use Claude Code for implementation
- Use manual review for validation
- Cache repeated patterns
- Batch related features

---

## Quality Standards

### Before Committing Code:
- [ ] Type hints present and accurate
- [ ] Docstrings explain *why*, not just *what*
- [ ] Tests pass (and actually test something meaningful)
- [ ] Error handling covers realistic failure modes
- [ ] Example usage included
- [ ] PKB references documented (which patterns informed this code)

### Before Marking a Capability "Complete":
- [ ] Works in isolation
- [ ] Integrates with at least one other capability
- [ ] Performance tested with realistic data volumes
- [ ] Failure modes documented
- [ ] Real-world example provided
- [ ] README updated

---

## GitHub Workflow

### Initial Push
```bash
# Initialize repo
cd C:\Users\Michal Valco\Documents\agentic_ai_development
git init
git add .
git commit -m "Initial commit: Complete PKB (12/12 docs)"

# Connect to GitHub
git remote add origin https://github.com/yourusername/agentic_ai_development.git
git branch -M main
git push -u origin main
```

### Development Branches
- `main` - Stable, working code only
- `dev` - Active development
- `feature/routing` - Individual capabilities
- `feature/testing` - Test infrastructure
- `docs/architecture` - Documentation work

### Commit Messages
```
feat(routing): Implement intent classifier with Anthropic
test(routing): Add integration tests for classifier
docs(architecture): Define system interfaces
fix(query): Handle SQL injection in query builder
refactor(common): Extract shared utilities to common module
```

### CI/CD (GitHub Actions)
```yaml
# .github/workflows/test.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: pip install -r requirements-dev.txt
      - name: Run unit tests
        run: pytest tests/unit -v
      # Integration tests run only on main branch
      - name: Run integration tests
        if: github.ref == 'refs/heads/main'
        run: pytest tests/integration -v -m llm_integration
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
```

---

## Communication with Claude Code

### Effective Task Descriptions

**âŒ Bad:**
"Build the routing system"

**âœ… Good:**
"Implement prompt routing capability using patterns from docs/PKB/anthropic_prompt_engineering.md and docs/PKB/langchain_agents.md. Create:
1. IntentClassifier class (uses Claude to classify user intent)
2. Router class (routes to appropriate handler based on intent)
3. Handler interface (defines contract for route handlers)
4. Tests (unit + integration)

Follow patterns in PKB for error handling and structured outputs."

### Providing Context

**Reference PKB Documents:**
- "Using the ReAct pattern from react_pattern.md..."
- "Following the tool orchestration approach in langchain_tools.md..."
- "Implement error handling as described in anthropic_tool_use.md..."

**Specify Quality Requirements:**
- "Include type hints for all parameters"
- "Add docstrings in Google style"
- "Create both unit tests (mocked) and integration tests (real LLM calls)"
- "Handle rate limits and API failures gracefully"

---

## Success Metrics

This project succeeds when:

**Technical:**
- âœ… All 5 capabilities implemented and tested
- âœ… >80% code coverage
- âœ… All integration tests passing
- âœ… Production-ready error handling
- âœ… Comprehensive documentation

**Practical:**
- âœ… Each capability can be dropped into a real project
- âœ… Examples demonstrate real-world use cases
- âœ… Failure modes are predictable and recoverable
- âœ… Cost tracking shows efficient LLM usage

**Strategic:**
- âœ… $1000 Claude Code credit fully utilized
- âœ… Repository teaches as much as it provides
- âœ… Clear path for future contributors
- âœ… Portfolio-worthy project demonstrating AI engineering skills

---

## Current Status

**Completed:**
- âœ… Phase 1: PKB Development (12/12 documents, ~12,000 lines)
- âœ… Project structure defined
- âœ… Development workflow established
- âœ… Quality standards documented

**In Progress:**
- ðŸ”„ Phase 2: Architecture Design (ARCHITECTURE.md in progress)
- ðŸ”„ GitHub repository initialization

**Next Steps:**
1. **Immediate:** Push PKB to GitHub
2. **Day 1:** Create ARCHITECTURE.md
3. **Day 2-11:** Rapid implementation with Claude Code
4. **Ongoing:** Production readiness and optimization

---

**Last Updated:** 2025-11-07  
**Status:** Phase 1 Complete âœ… | Phase 2 In Progress ðŸ”„ | Phase 3 Starting (Claude Code Sprint)  
**Credit Deadline:** November 18, 2025 (11 days remaining)  
**Budget:** $1000 Claude Code credit allocated for rapid implementation